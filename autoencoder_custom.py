# -*- coding: utf-8 -*-
"""tlvgg16customdtst.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jsPtXefG40UvpFOuebv_2HKCn5D5O0TC
"""

from keras.layers import Conv2D, UpSampling2D, Input
from keras.models import Sequential, Model
from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from skimage.color import rgb2lab, lab2rgb, gray2rgb
#from skimage.transform import resize
#from skimage.io import imsave
import numpy as np
import tensorflow as tf
import keras
#import os


import glob
import cv2
from random import choice

from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D
from tensorflow.keras.models import Sequential

from skimage.metrics import structural_similarity as ssim ,mean_squared_error as mse, peak_signal_noise_ratio

folder_list = ['berry','bird','dog','flower','other','berrya','birda','doga','flowera','othera']
clean_images = []
noisy_images = []
std_list = [0.05,0.10,0.25]
mean = 0
size = 224

#for folder in folder_list :
    #path = r"/floyd/input/customdata/customimagestrain/"+folder+"/*.jpg"
path = r"E:/work/autoencoder/dataset/berry/*.jpg"
print(path)
for file in glob.glob(path):  
        a = cv2.imread(file,0)   #now, we can read each file since we have the full path
        a = cv2.resize(a,(224,224))
        sigma = choice(std_list)
        noise = np.random.normal(mean,sigma,(size,size))   #ch
        noise = noise.reshape(size,size)
        a_noisy = a + (a * noise)
        clean_images.append(np.array(a))
        noisy_images.append(np.array(a_noisy))

print(len(clean_images))

print(len(noisy_images))

clean_images = np.reshape(clean_images, (len(clean_images), size,size, 1))
clean_images = clean_images.astype('float32') / 255

noisy_images = np.reshape(noisy_images, (len(noisy_images), size, size, 1))
noisy_images = noisy_images.astype('float32') / 255

#clean_images = np.reshape(clean_images, (len(clean_images), size,size,1))


#noisy_images = np.reshape(noisy_images, (len(noisy_images), size, size,1))

noisy_images.shape

clean_images.shape

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(noisy_images, clean_images, 
                                                    test_size = 0.20, random_state = 0)



model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(size, size, 1)))
model.add(MaxPooling2D((2, 2), padding='same'))
model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D((2, 2), padding='same'))
model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))
 

model.add(MaxPooling2D((2, 2), padding='same'))
     
model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))
model.add(UpSampling2D((2, 2)))
model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))
model.add(UpSampling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(UpSampling2D((2, 2)))
model.add(Conv2D(1, (3, 3), activation='relu', padding='same'))

model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])

model.summary()

model.fit(x_train, y_train, epochs=100, batch_size=128, shuffle=True, verbose = 1,
          validation_split = 0.1)
model.save('denoise_autoencoder_custom2.model')

print("Test_Accuracy: {:.2f}% ".format(model.evaluate(np.array(x_test), np.array(y_test))[1]*100))
'''

model = tf.keras.models.load_model('E:/work/autoencoder/denoise_autoencoder_VGG16.model',
                                   custom_objects=None,
                                   compile=True)
'''
model.compile(optimizer='Adam', loss='mse' , metrics=['accuracy'])
no_noise_img = model.predict(x_test)


import matplotlib.pyplot as plt


plt.imshow(no_noise_img[3].reshape(224,224), cmap="gray")
plt.show()
import matplotlib.pyplot as plt
plt.imshow(x_test[3].reshape(224,224), cmap="gray")
plt.show()
import matplotlib.pyplot as plt
plt.imshow(y_test[3].reshape(224,224), cmap="gray")
plt.show()


